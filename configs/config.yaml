# Network Configuration
network:
  n_users: 10
  n_rbs: 20
  max_steps_per_episode: 100
  bandwidth_per_rb: 180000  # Hz
  tx_power: 23  # dBm
  noise_power_dbm: -104  # dBm
  user_distance_range: [10, 500]  # meters

# PPO Hyperparameters
ppo:
  learning_rate: 0.0003
  n_steps: 2048
  batch_size: 64
  n_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5

# Training Configuration
training:
  total_timesteps: 300000  # Increased for better convergence
  eval_frequency: 10000
  n_eval_episodes: 50  # More episodes for statistical significance
  save_frequency: 50000
  log_dir: "results/logs"
  model_save_path: "results/models"

# Attack Configuration - MORE AGGRESSIVE
attack:
  attack_type: "cqi_falsification"
  attack_probability: 0.4  # 40% malicious users (was 0.3)
  noise_magnitude: 0.7  # Stronger perturbation (was 0.5)
  attack_start_step: 0

# Defense Configuration
defense:
  method: "adversarial_training"
  adversarial_training:
    poison_ratio: 0.3  # Increased from 0.2
  anomaly_detection:
    threshold: 2.0  # More sensitive (was 2.5)
    window_size: 10
  input_validation:
    cqi_bounds: [0.0, 1.0]
    buffer_bounds: [0.0, 1.0]
    rate_limit: 0.15  # Allow slightly larger changes (was 0.1)

# Evaluation Configuration
evaluation:
  scenarios:
    - name: "baseline"
      attack_enabled: false
      defense_enabled: false
    - name: "under_attack"
      attack_enabled: true
      defense_enabled: false
    - name: "with_defense"
      attack_enabled: true
      defense_enabled: true
  metrics:
    - throughput
    - latency
    - fairness
    - packet_loss